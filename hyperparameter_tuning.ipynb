{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJXQakaIXtPz"
   },
   "source": [
    "# Hyperparameter tuning using Optuna \n",
    "resources:\n",
    "1. https://aetperf.github.io/2021/02/16/Optuna-+-XGBoost-on-a-tabular-dataset.html\n",
    "2.https://medium.com/optuna/using-optuna-to-optimize-xgboost-hyperparameters-63bfcdfd3407#:~:text=Optuna%20is%20a%20hyperparameter%20optimization,highly%20efficient%2C%20flexible%20and%20portable.\n",
    "3.https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb67a1UhYw_V",
    "outputId": "c617dbdc-1e29-4bd8-bf28-8d2072012d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.7)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.35)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.8.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.0)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# install optuna\n",
    "\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "h-lO8czLUPX4"
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import XGBoostPruningCallback, LightGBMPruningCallback\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Lehm_Mu2I79r"
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv('./train_E1GspfA.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "PH7oDWiMU73R"
   },
   "outputs": [],
   "source": [
    "# set datetime as index\n",
    "\n",
    "train.set_index(pd.to_datetime(train.date) + pd.to_timedelta(train.hour, unit='h'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "9ABLHCytgiks"
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "# train\n",
    "X_train = train.loc['2018':'2020'].drop(columns=['demand']).copy()\n",
    "y_train = train.loc['2018':'2020', 'demand'].values.copy()\n",
    "\n",
    "# test\n",
    "X_test = train.loc['2021'].drop(columns=['demand']).copy()\n",
    "y_test = train.loc['2021', 'demand'].values.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTC8on8zV02u"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Zo9G9Bf6VD08"
   },
   "outputs": [],
   "source": [
    "# convert datetime to day, month, year\n",
    "\n",
    "def convert_datetime_to_day_month_year(df):\n",
    "    \n",
    "    date_col = df.index\n",
    "    \n",
    "    df['day'] = date_col.day\n",
    "    df['month'] = date_col.month\n",
    "    df['year'] = date_col.year\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "6W5lbSeiV40A"
   },
   "outputs": [],
   "source": [
    "# get day of week\n",
    "\n",
    "def day_of_week(df):\n",
    "    \n",
    "    date_col = df.index\n",
    "    \n",
    "    df['day_of_week'] = date_col.weekday\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-2J9RZmXV7xD"
   },
   "outputs": [],
   "source": [
    "# if weekend or weekday\n",
    "\n",
    "def is_weekend(df):\n",
    "    \n",
    "    date_col = df.index\n",
    "    \n",
    "    df['is_weekend'] = np.where(df['day_of_week']<5, 0, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "I4CQnD8KV8e9"
   },
   "outputs": [],
   "source": [
    "# week of year\n",
    "\n",
    "def week_of_year(df):\n",
    "    \n",
    "    date_col = df.index\n",
    "    \n",
    "    df['week_of_year'] = date_col.isocalendar().week.astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "GAa_RX1baZQN"
   },
   "outputs": [],
   "source": [
    "# Add holidays\n",
    "\n",
    "def is_holiday(df):\n",
    "    \n",
    "    date_col = df.index.date\n",
    "    \n",
    "    Indian_holidays = holidays.India()\n",
    "    US_holidays = holidays.US()\n",
    "    \n",
    "    df['is_holiday'] = [1 if (i in Indian_holidays) | (i in US_holidays) else 0 for i in date_col]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "i0ZQU5hJV9Qz"
   },
   "outputs": [],
   "source": [
    "# whether it is day or night\n",
    "\n",
    "def is_day(df):\n",
    "    \n",
    "    df['is_day'] = df.apply(lambda row: 1 if (row['hour']>=6 and row['hour']<=18) else 0, axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "cnlPF_qzV9hZ"
   },
   "outputs": [],
   "source": [
    "# seasons\n",
    "\n",
    "def which_season(df):\n",
    "    \n",
    "    df['season'] = df.month%12 // 3 + 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "K3x_utBbe6eJ"
   },
   "outputs": [],
   "source": [
    "# convert hour to sin and cosine components\n",
    "\n",
    "def cyclic_hour(df):\n",
    "    \n",
    "    hours_in_day = 24\n",
    "    \n",
    "    df['sin_hour'] = np.sin(2.*np.pi*df['hour']/hours_in_day)\n",
    "    df['cos_hour'] = np.cos(2.*np.pi*df['hour']/hours_in_day)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "3U3hS9ubfBHL"
   },
   "outputs": [],
   "source": [
    "# convert days of week into sin and cosine component\n",
    "\n",
    "def cyclic_week(df):\n",
    "    \n",
    "    # monday = 0, sunday = 6\n",
    "    days_in_week = 6\n",
    "    \n",
    "    df['sin_week'] = np.sin(2.*np.pi*df['day_of_week']/days_in_week)\n",
    "    df['cos_week'] = np.cos(2.*np.pi*df['day_of_week']/days_in_week)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "C-Q14wF7fDXj"
   },
   "outputs": [],
   "source": [
    "# convert months into sin and cosine components\n",
    "\n",
    "def cyclic_month(df):\n",
    "    \n",
    "    months_in_year =12\n",
    "    \n",
    "    df['sin_month'] = np.sin(2.*np.pi*df['month']/months_in_year)\n",
    "    df['cos_month'] = np.cos(2.*np.pi*df['month']/months_in_year)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6ha9iwrVYQO-"
   },
   "outputs": [],
   "source": [
    "# Add new features\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    # add day, month, year\n",
    "    df = convert_datetime_to_day_month_year(df)\n",
    "    \n",
    "    # day of week\n",
    "    df = day_of_week(df)\n",
    "    \n",
    "    # is weekend\n",
    "    df = is_weekend(df)\n",
    "    \n",
    "    # week of year\n",
    "    df = week_of_year(df)\n",
    "    \n",
    "    # add holidays\n",
    "    df = is_holiday(df)\n",
    "    \n",
    "    # is day\n",
    "    df = is_day(df)\n",
    "    \n",
    "    # which season\n",
    "    df = which_season(df)\n",
    "    \n",
    "    # # cyclic features\n",
    "    df = cyclic_hour(df)\n",
    "    df = cyclic_month(df)\n",
    "    df = cyclic_week(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "96NfZp9nt-MV"
   },
   "outputs": [],
   "source": [
    "# add new features\n",
    "\n",
    "X_train_features = add_features(X_train)\n",
    "X_train_features.drop(columns=['date'], inplace=True)\n",
    "\n",
    "X_test_features = add_features(X_test)\n",
    "X_test_features.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "_W-cM1YpYupD"
   },
   "outputs": [],
   "source": [
    "# objective\n",
    "\n",
    "def objective (trial, model, X_train, y_train, X_test, y_test,\n",
    "               random_state = 42, n_jobs = -1, early_stopping_rounds =100):\n",
    "\n",
    "  # XGBoost parameters\n",
    "  xgb_params = {\n",
    "      'tree_method': 'gpu_hist',\n",
    "      'verbosity': 0,\n",
    "      'objective':'reg:squarederror',\n",
    "      'n_estimators': 10000,\n",
    "      'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "      'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "      'subsample': trial.suggest_loguniform('subsample', 0.6, 0.8),\n",
    "      'min_child_weight': trial.suggest_loguniform('min_child_weight', 10, 100)\n",
    "      }\n",
    "  \n",
    "  # LightGBM parameters\n",
    "\n",
    "  lgbm_params = {\n",
    "      # \"device_type\": 'gpu',\n",
    "      \"n_estimators\": trial.suggest_int(\"n_estimators\", 500,1000, step=100),\n",
    "      \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "      \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "      \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "      \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "      \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "      \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 0.8, step=0.1),\n",
    "      \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "      \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 0.8, step=0.1)\n",
    "      }\n",
    "\n",
    "\n",
    "  if model == 'xgb':\n",
    "  \n",
    "    # xgb\n",
    "    xgb_model = XGBRegressor(** xgb_params)\n",
    "\n",
    "    # prune not promising trails based on eval_set rmse\n",
    "    xgb_pruning_callback = XGBoostPruningCallback(trial, 'validation_0-rmse')\n",
    "\n",
    "    xgb_model.fit(X_train, y_train, \n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric = 'rmse',\n",
    "            callbacks = [xgb_pruning_callback],\n",
    "            early_stopping_rounds= early_stopping_rounds,\n",
    "            )\n",
    "    \n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "  elif model == 'lgbm':\n",
    "\n",
    "    # lightGBM\n",
    "    lgbm_model = LGBMRegressor(** lgbm_params)\n",
    "\n",
    "    # prune not promising trails based on eval_set rmse\n",
    "    lgbm_pruning_callback = LightGBMPruningCallback(trial, 'rmse')\n",
    "\n",
    "    lgbm_model.fit(X_train, y_train,\n",
    "                  eval_set =[(X_test, y_test)],\n",
    "                  eval_metric = 'rmse',\n",
    "                  callbacks = [lgbm_pruning_callback],\n",
    "                  early_stopping_rounds = early_stopping_rounds,\n",
    "                  )\n",
    "    \n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "    \n",
    "  else:\n",
    "\n",
    "    print('Provide a valid model name')\n",
    "  \n",
    "  return mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDnSKr2SGeNV"
   },
   "outputs": [],
   "source": [
    "# sampler\n",
    "\n",
    "sampler = TPESampler(seed = 42, multivariate=True)\n",
    "\n",
    "# study\n",
    "\n",
    "model = 'lgbm'\n",
    "study = create_study(direction='minimize', sampler=sampler, study_name = f'{model}_tuning')\n",
    "study.optimize(\n",
    "    lambda trial:\n",
    "    objective(trial, model, X_train_features, y_train, X_test_features, y_test),\n",
    "    n_trials = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKMwiiaozw8X",
    "outputId": "710511a2-a34d-42b1-a2ac-beb951061657"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.30000000000000004,\n",
       " 'bagging_freq': 1,\n",
       " 'feature_fraction': 0.7,\n",
       " 'lambda_l1': 65,\n",
       " 'lambda_l2': 55,\n",
       " 'learning_rate': 0.09639177677050871,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 71.89768582681245,\n",
       " 'min_data_in_leaf': 100,\n",
       " 'n_estimators': 1000,\n",
       " 'num_leaves': 80,\n",
       " 'subsample': 0.6854090170878597}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JntaQQRYIxdb",
    "outputId": "6254be2f-4d62-447e-eb34-f0f4a8857b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           max_depth : 9\n",
      "       learning_rate : 0.09639177677050871\n",
      "           subsample : 0.6854090170878597\n",
      "    min_child_weight : 71.89768582681245\n",
      "        n_estimators : 1000\n",
      "          num_leaves : 80\n",
      "    min_data_in_leaf : 100\n",
      "           lambda_l1 : 65\n",
      "           lambda_l2 : 55\n",
      "    bagging_fraction : 0.30000000000000004\n",
      "        bagging_freq : 1\n",
      "    feature_fraction : 0.7\n",
      "best objective value : 32.7397257590521\n"
     ]
    }
   ],
   "source": [
    "# display params\n",
    "\n",
    "best_params = study.best_params\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key:>20s} : {value}\")\n",
    "print(f\"{'best objective value':>20s} : {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "uuaitYIpyr31"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
